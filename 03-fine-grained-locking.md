# Fine-grained Locking

Используя мьютексы, уже можно сделать потокобезопасной любую структуры данных: в начале каждого метода ставим `lock`, а в конце `unlock`.
Но это полное отсутствие парелльности, а производительность только упадет.

Когда мы используем мьютекс в таком виде, мы полностью защищаем структуру данных от ее изменения другими потоками. Попробуем защищать ее не целиком, а по независимым частям. Такой способ блокировки называют _мелкогранулярными блокировками_.

## Задача об обедающих философах

О чем следует думать, если много `lock`'ов.

Есть 5 философов (потоки) которые сидят за круглым столом и едят.
Между двумя соседними философами лежит 1 вилка (мьютекс).
Чтобы философу поесть, ему нужно взять вилку справа и слева от себя, поесть и положить обе вилки обратно.
Как им нужно брать вилки, чтобы все они смогли поесть?

### Способ 1

```C++
left_fork.lock();
right_fork.lock();
```
Ясно, что этот способ не работает, потому что если возьмут одну левую вилку, то произойдет дедлок и взаимная блокировка.

### Способ 2

```C++
while (/*не поел*/) {
  left_fork.lock();
  if (right_fork.try_lock()) {
    // едим
  } else {
    left_fork.unlock();
  }
}
```

Здесь нет дедлока, однако есть взаимная блокировка: существует исполнение, в котором ни один из философов так и не сможет поесть.
Например, все поочередно берут левую вилку, затем пробуют взять правую, у всех не получилось, так что все отпускают левые вилки, а потом заново их берут и так далее.
Такая ситуация, где есть каждый поток имеет какой-то локальный прогресс, но глобальный прогресс отсутствует, называются _лайвлоками_ (livelock).

### Способ 3

Предлагается доказать, что взаимных блокировок не будет, если использовать способ 1, однако условиться, что один филосов сначала берет правую вилку, а затем левую (философ-правша).
Это одно из возможных решений проблемы.

## Wait-for Graph

Рассмотрим вспомогательную конструкцию, Wait For Graph.
В нем есть два типа вершин: `T_i` - потоки, `M_j` - мьютексы.
Ребра зависят от состояния системы следующим образом: если `T_i` хочет захватить мьютекс `M_j`, то ребро `(T_i, M_j)`, если мьютекс `M_j` захвачен потоком `T_i`, то ребро `(M_j, T_i)`.
Есле же ничего не происходит или вызывается `unlock`, то ребра нет.

Оказывается, цикл в таком графе равносилен наличию дедлка.
Если мьютекс отслеживает этот граф, то он сам может обнаруживать дедлоки.

Простейшая ситуация приведена на примере.

`T_1`      | `T_2`
---------- | ----------
`A.lock()` | ...
...        | `B.lock()`
`B.lock()` | ...
...        | `A.lock()`

Естественно, это взаимная блокировка, и Wait-for Graph имеет следующий вид.  
<!--![Цикл в Wait-for Graph](images/simple-wait-for-graph-cycle.jpg)-->

Оказывается, можно избежать дедлоков, если ввести на мьютексах глобальный порядок и захватывать только тот мьютекс, номер которого строго больше, чем номера всех захваченных мьютексов.
Действительно, обозначим через `L(M_j)` номер мьютекса.
Предположим, в алгоритме, удовлетворяющем вышеописанному свойству, появился дедлок.
Тогда в Wait for Graph'е существует цикл, для определенности `T_1 -> M_1 -> T_2 -> M_2 -> ... -> M_k -> T_1`.
Заметим, что в соответствии с определением ребра вида `(T_i, M_i)` означают желание захватить мьютекс, а ребра вида `(M_i, T_(i+1))` принадлежность мьютекса потоку.
Положим `L(T) = max{L(M) | M -> T}` - номер максимального мьютекса, захваченного потоком `T`. Тогда по описанию алгоритма `L(T_1) < L(M_1)` (можем хотеть захватить только мьютекс, номер которого больше номеров всех захваченных), а `L(M_1) <= L(T_2)` по определению числа `L`.
Отсюда `L(T_1) < L(T_2)`.
Тогда, продолжая цепочку неравенств, приходим к противоречию.

## Hash Table

Попытаемся реализовать контейнер с мелкогранулярными блокировками.

### Общие идеи

Hash Table поддерживает три операции: `Insert(x)`, `Remove(x)`, `Containts(x)`.
При этом элемент не добавляется, если уже содержится.
Элементы хранятся в виде контейнера типа, хранящего `m` односвязных списков; они называются _бакетами_ (bucket).
Чтобы понять, куда следует добавить элемент `x`, используется _хеш-функция_ `h : U -> N`, сопоставляющая каждому элементу некоторое натуральное число.
Тогда элемент `x` кладется в бакет `h(x) mod m`.

Интуиция состоит в том, что с разными бакетами можно работать параллельно, так как они не связываются друг с другом.
Идея: пусть каждый мьютек отвечает за какой-то кусок бакетов хеш-таблицы.
Здесь мьютексы будем называть `локами`.
Для работы с бакетом нужно взять взять лок, который за него отвечает.

У нас один лок будет отвечать за несколько бакетов, поскольку отношение 1 к 1 добиться сложно.
Помним, что есть `load_factor := size / m`, при превышении которым некотррого порогового значения нужно расширять хеш-таблицу, то есть добавлять новые бакеты (кстати, для `size` нужен атомик).
Но если еще при этом добавлять локи, то будет полный ад.

### Как расширять Hash Table

При расширении хеш-таблицы затрагиваются все ее элементы.
Исторически сложилось, что расширением занимается тот поток, который переполнил таблицы.
Поэтому ему для расширения необходимо получить монопольный доступ ко всей таблицы.
В момент переполнения один лок он уже держит, но просто пройтись по оставшимся и захватить их не выходит: возникает простой дедлок при переполнении двумя потоками.
Однако если **отпустить свой мьютекс, а потом пройтись по всем из них сначала и захватить**, то дедлоков не будет по тому утверждению, которое мы доказывали с помощью Wait for Graph'а.

Следующая проблема состоит в том, что таблицу могут расширить дважды, ибо другие потоки, переполнившие таблицу, не знают, вдруг она уже расширилась и больше не переполнена.
Для решения можно думать, как сравнивать версии таблицы или заново считать `load_factor`.
Однако мы знаем, что если мьютекс взяли, то точно ее никто не мог расширить.
Поэтому **после захвата первого мьютекса проверяем актуальное значение `load_factor`'а и в случае необходимости отказываемся от расширения.**

#### Лирическое отсутпление

Вообще говоря, так все равно плохо, потому что один поток монопольно владеет всей таблицей.
Самые быстре хеш-таблицы умеют параллельно переносить данные из одной памяти в другую (параллельные миграции).

Есть аналогия со сборщиком мьютекса.
Для них известно два подхода:  

1. сначала маркируем все достижимые состоянии, потом стираем все остальные;  

1. (копирующий сборщик мусора) маркируем все состояние, достижимые копируем в новое место.

Есть распараллеленный marking, однако копирование пока что хорошо не получается (хотя что-то там уже придумано); используется метод stop-the-world: тупо останавливается вообще все на свете, и только тогда оно копируется.

Параллельные миграции хеш-таблицы очень похожи на распаллеливание копирования в gargabe collector'е.

***

У нас пока есть еще проблемы.
Пусть оракул сказал захватить такой-то лок.
Но он занят, а у нас произошло перехеширование, и данный лок теперь защищает другой бакет.

Есть несколько путей решения.
Обозначим через `n` число локов.

#### Способ 1

Локи связаны не с бакетами, а с элементами: `L(x) = h(x) mod n` - номер соответствующего лока.
Но может возникнуть проблема: пусть есть бакет, где лежит элемент `x`, но в односвязном списке вместе с ним еще есть элемент `y`, защищаем другим локом.
Таким образом, для работы с элементом `x` нужно брать и другие локи тоже, и вообще все непонятно.
Идея не взлетела.

#### Способ 2

Бакеты все же привязаны к локам.
Номер бакета считаем по формуле `B(x) = h(x) mod m`, но число бакетов можем не знать из-за расширения.
Идея в том, чтобы сделать дополнительный лок, который блочится в самом начале, из-за чего расширение невозможно.
Но тогда через него проходят все потоки, а это уже полное отсутствие параллельности.

#### Способ 3

А если захватывать не особенный лок, а просто какой-то другой рандомный из имеющихся, то можно получить дедлок.

#### Способ 4

Идея: при перехешировании разрешим бакету может меняться, а страйпу нет.
Тогда можно просто перейти в другой бакет, все равно с ним никто не работал.

Например, пусть `n = 3`, `m = 3` и лок `i` защищает бакет `i`. Расширяем в два раза: появилось три новых бакета. Давайте бакет `i` будет защищаться локом `i mod n`.

Формула: `B(x) = h(x) mod m`, а `L(x) = B(x) mod n`, откуда `L(x) = (h(x) mod m) mod n`.
Но здесь нужно быть аккуратным: при нудачном расширении номер лока может поменяться. Например, в предыдущем примере если расширять не с 3 до 6, а с 3 до 6, то все станет плохо.
**Нужно поддерживать `m = kn`.** Действительно, тогда `L(x) = (h(x) mod kn) mod n = h(x) mod n`.
А мы это пробовали в начале, но не взлетело, потому что мы не думали тогда о расширениях
Теперь же все хорошо; вообще у нас каждый бакет распадается на несколько новых бакетов, защищаемых тем же локом.

### Reader/Writer Mutex

> Много локов - большая ответственность. (Р. Липовский)

Вообще мы достигли не очень больших высот, так как при расширении все равно теряется параллельность.

Заметим, что если одновременно использовать `Insert` и `Remove`, то все вообще плохо, но несколько одновременных `Contains` совершенно без проблем существуют вместе.

RW Mutex имеет 2 пары операций: `writer_lock`, `writer_unlock`, `reader_lock`, `reader_unlock` - и поддерживает инварианты:

1. writer-секции не пересекаются ни с какими другими;
2. reader-секции могут выполняться одновременно.

Напишем его дома или на семинаре.

В `Insert`, `Remove` и расширении будем вызвать writer-методы, а в `Contains` - reader.

## Анонс будущих лекций

Мы научимся писать Concurrent Singly-linked Sorted List - многопоточный односвязный отсортированный список
Их можно применить к хеш-таблице и использовать как бакеты.
Но локи с верхнего уровня убирать не надо, поскольку они все равно нужны для расширения.
У нас получится использовать reader-секции везде, кроме расширения.

Отсортированность списка понадобится по двум причинам:

1. знаем, где находится элемент (с каким ребром в односвязном списке придется работать);

2. можно делать клевые `lower_bound` и т. п.

Так может получиться `set`.
Почему вообще мы пишем на списках?
В STL он на красно-черном дереве.
Однако если у нас есть поддерево с большой глубиной, то происходит балансировка (вращение).
По-видимому, чтобы делать ее параллельно, нужно блокироваться при работе с узлами.
Но как это сделать без дедлоков?
Если выбрать какой-то естественный порядок для узлов, то он все равно поменятся на неудачный при балансировке.
