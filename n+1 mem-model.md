# Memory [Consistency] Model

## Ожидание

Программист ожидает глобальный порядок всех чтений и записей, который
согласован с порядком операций каждого потока.

Можно доказать корректность всяких разных алгоритмов.

### Мьютекс Петерсона

Поток 0
```c++
want[0] = true
victim = 0
while want[1] and victim == 0:
	// wait
```

Поток 1
```c++
want[1] = true
victim = 1
while want[0] and victim == 1:
	// wait
```

Предположим, что взаимное исключение нарушилось, и два
потока вошли в критическую секцию.
Пусть последним в victim сделал запись поток T1:

T0: want[0] = true → 
T0: victim = 0 → 
T1: want[0] == true → 
T1: victim = 1

### Оптимистичный список

![mem-model-001.png]

Порядок на обращениях к памяти ⇒ порядок на мутациях
ссылок ⇒ доказываем инварианты

## Реальность

В реальности никто не гарантирует вашей программе
последовательного исполнения.
Программа, которую вы написали, и программа, которую
исполнил процессор - это две разные программы!

Программа → Компилятор → Процессор

Вы написали в программе b = a + 1; a = 1; и полагаете, что
запись b выполнится раньше, чем запись a, ведь между ними
точка-с-запятой!

### Реордеринги в компиляторе
Любой современный компилятор является оптимизирующим, и эти оптимизации могут быть самыми разными (устранение хвостовой рекурсии, удаление ненужных присваиваний, инайнинг функций, ...). Более того, компилятор на каком-то этапе своей работы генерирует трёхпозиционный (похожий на ассемблерный) код, и там оптимизирует порядок выполнения отдельных команд. Его не беспокоит, что компилируемый код будет работать в нескольких потоках. Проводя оптимизации, он заботится лишь о том, чтобы не сломать поведение однопоточной программы.

![mem-model-002.png] ![mem-model-003.png]

x86, gcc 4.8.1, -O2

При этом, относительный порядок записей в разные ячейки памяти
критичен при синхронизации:
Поток 1
```
data = 42
ready = true
```

Поток 2
```
if (ready) {
	assert data == 42
}
```

### Реордеринги в процессоре
Процессор может менять порядок исполнения с ещё более запутанной логикой.
Выдержка из Intel \textregistered 64 and IA-32 Architectures Software Developer’s Manual:
![mem-model-004.png]

К чему это может привести? 
Изначально x = y = 0
Поток 1
```
x = 1
r1 = y
```
```
Поток 2
y = 1
r2 = x
```

Все последовательные исполнения:
```
x = 1
y = 1
r1 = y
r2 = x
```
```
x = 1
y = 1
r2 = x
r1 = y
```
```
x = 1
r1 = y
y = 1
r2 = x
```

y = 1
x = 1
r1 = y
r2 = x

y = 1
x = 1
r2 = x
r1 = y

y = 1
r2 = x
x = 1
r1 = y

Нетрудно заметить, что $r1 == 1 \vee r2 == 1$.

Нужно ли переживать из-за исхода $r1 == r2 == 0$?
Да! Всё ломается!


#### Мьютекс Петерсона
Поток 1
want[0] = 1
victim = 0
r1 = want[1]

Поток 2
want[1] = 1
victim = 1
r2 = want[0]

...

...

↓
Поток 1
want0 = 1
r1 = want1

Поток 2
want1 = 1
r2 = want0

Результат r1 == r2 == 0 приведет к тому, что два потока
вместе войдут в критическую секцию!

### Порядок записи в память

У процессора есть оптимизация Store Buffer

Поток 1
x = 1
r1 = y

Поток 2
y = 1
r2 = x

Чтение r1 = y переупорядочилось с записью x = 1.

Потоки на двух процессорах наблюдают разные истории записи
в общую память.
Память не атомарна!

## Другие архитектуры
Архитектура x86 допускает только один вид реордерингов:
Последующий load может обогнать предыдущий store,
если они обращаются к разным ячейкам памяти.

На других архитектурах все еще интереснее:

## Memory Model

Модель [консистентности] памяти – это набор правил, который регламентирует взаимодействие многопоточной программы с разделяемой памятью.

Модель памяти отвечает на вопросы:
1. В каком относительном порядке происходят обращения к памяти (чтения и записи) из разных потоков?
2. Какое значение прочитает произвольное чтение в программе?
Два аспекта – ordering и visibility.

Hardware Memory Model
* Чаще всего сложная и неинтуитивная
* Не всегда хорошо документирована
* Своя для каждой архитектуры
* В ней очень сложно проводить формальные доказательства и строить инварианты
* Зато позволяет процессору выполнять программу быстрее (и не важно, что при этом происходит с программой...)

Нужен общий знаменатель!

### Sequential Consistency
Придумал Leslie Lamport, 1979, "How to Make a Multiprocessor Computer That Correctly Executes Multiprocess Programs"

Результат любого исполнения программы такой же, как при
некотором последовательном исполнении операций, в котором
операции каждого потока исполнялись бы в соответствии с их
порядком в программе.

Что значит "такой же"?
Наблюдать мы можем только результаты чтений.
Значит, гарантируется, что все чтения вернут тот же результат, что и при некотором последовательном исполнении.

Простое наблюдение:
Можно исполнять программу не совсем последовательно, что-то переупорядочивать, лишь бы результат совпадал с результатом некоторого последовательного исполнения.

Последовательно согласованное исполнение $\ne$ Последовательное исполнение

### Модель чередования


Последовательная согласованность позволяет моделировать
исполнения программы с помощью модели чередования
потоков на единственном процессоре.

![mem-model-011.png]

В модели нет параллельности!

Замечание. Гарантировать для произвольной программы только последовательно согласованные исполнения дорого.

Решение - SC-DRF
### Sequential Consistency for Data-Race-Free Programs (SC-DRF)

Будем гарантировать последовательно согласованные
исполнения не для всех программ, а только для корректно
синхронизированных.

Если в программе нет гонок (data-race-free), то результат ее исполнения не будет отличаться от некоторого последовательного исполнения.

SC-DRF – контракт между программистом и производителем процессора / разработчиком компилятора:
* Программист обязуется написать корректно синхронизированную (в рамках модели) программу
* Компилятор + процессор обещают выполнить эту программу так, чтобы программист не смог отличить исполнение от последовательного.

Контракт фиксируется в стандарте языка программирования в виде модели памяти. Реализуют контракт разработчики компилятора и процессора.
* Разработчики процессора описывают правила упорядочивания обращений к памяти и предоставляют специальные инструкции, с помощью которых можно влиять на порядок – барьеры памяти.
* Компилятор расставляет эти барьеры в коде, полагаясь на корректность программы.

Что будет, если программист нарушит контракт?

### Будем изучать модель памяти изнутри

Какие минимальные гарантии упорядочивания нужно обеспечить при исполнении программы, чтобы
* программист не смог отличить исполнение от последовательного,
* процессор мог бы выполнять разные оптимизации?

Цели противоположные: с одной стороны, обеспечить порядок, с другой – уйти от жесткого порядка.

Перед нами программа, в которой несколько потоков и много обращений к памяти. Для простоты – только чтения и записи. Попытаемся понять, для каких обращений к памяти нужен жесткий порядок исполнения, а для каких – нет.

Два обращения к памяти конфликтуют, если:
* Они обращаются к одной и той же ячейке памяти
* По крайней мере одно из этих обращений – запись

Ситуацию, когда конфликтующие обращения к памяти
конкурируют друг с другом, будем называть гонкой.

Гонки – это всегда плохо? Нет. Иногда они полезны.

Гонки – сама суть синхронизации:
Мьютекс Петерсона
want[0] = true
victim = 0
while want[1] and victim == 0:
// wait

want[1] = true
victim = 1
while want[0] and victim == 1:
// wait

Где здесь гонки?
* Записи в victim
* Запись и чтение флажков

Подобные обращения к памяти необходимо глобально
упорядочить, иначе мы не сможем реализовать мьютекс!

### Обращения к памяти

Выделим подмножество переменных, которые используются для синхронизации, и назовем их атомиками, а обращения к этим переменным – synchronization actions. 

Программист должен сам аннотировать эти переменные:
В C++: std::atomic<T> + std::memory_order_seq_cst, в Java: volatile.

Обращения ко всем остальным переменным назовем data actions.

#### Порядок на synchronization actions

Потребуем последовательного исполнения для synchronization actions.
Линейный порядок на них назовем synchronization order, −so→.
−so→ должен быть согласован с −po→ (program order), иначе поломается логика наших программ.

Вообще-то мы хотели избежать последовательного исполнения!

Death Star

Последовательное исполнение необходимо, но только на
подмножестве обращений к памяти.

Порядок на data actions - интуиция

Для синхронизации нам нужен линейный порядок
подмножестве переменных.

−so→ на

Для всех остальных обращений к памяти глобальный порядок не требуется!
Нужно лишь гарантировать, что чтения, которые зависят по логике программы от каких-либо записей, увидят результат этих записей.

Пример зависимости

data – данные, которые один поток хочет передать другому,
ready – флаг для синхронизации.

Поток 1
data = "Hello!"
ready = true

Поток 2
while (!ready) {}
assert data == "Hello!"

Если поток увидел ready == true, то он должен прочитать из
data строку "Hello!".

Зависимости между записями и чтениями

Нужно найти зависимости!

Зависимости между записями и чтениями

Нам потребуется идея из мира распределенных систем.

Модель обмена сообщениями
В распределенных системах нет общей памяти, участники
(узлы) общаются отправляя и получая сообщения.

Общих часов тоже нет, и нельзя установить глобальный
порядок событий.

Happens-Before в распределенных системах
Если событие a предшествовало событию b на одном узле, то
a −→ b
hb

Если один узел отправил (событие a) другому узлу сообщение,
а тот его получил (событие b), то
a −→ b
hb

Дальше замыкаем по транзитивности.
Получаем happens-before – частичный порядок на событиях
в системе.
Есть несравнимые события – c

‖ d.

Happens-Before в распределенных системах
Частичный порядок happens-before отражает причинность:
a −→ b означает, что событие a могло повлиять на событие b.
hb

При этом есть пары событий, которые в смысле причинности
независимы, c ‖ d.

Happens-Before для модели памяти

Перенесем отношение happens-before на многопоточные
программы.

Program-Order
«Произошло до» в пределах одного потока – это program
order, порядок инструкций в тексте программы.

a −→ b, если a и b из одного потока, и a предшествует b в
тексте программы.
po

Передача сообщения

Какой аналог у передачи сообщения в модели с
разделяемой памятью?

Передача сообщения

Какой аналог у передачи сообщения в модели с
разделяемой памятью?

Поток прочитал запись, сделанную другим потоком.

Synchronizes-With

Пусть a и b – два synchronization actions: a – запись в
некоторую ячейку x, b – чтение из этой ячейки в другом
потоке.
a −→ b, если чтение b прочитало значение, записанное
записью a.
sw

Synchronizes-With
Стрелка −→ возникает или не возникает в зависимости от
исполнения:
sw

Поток 1
data = 42
ready = true

Фактически,

Поток 2
if (ready) {
assert data == 42
}

sw
so
−→
определяется отношением −→.

Program-Order и Synchronizes-With

sw
−po→ и −→
– отношения частичного порядка на обращениях к

памяти.

Отношение −→ – статическое, определяется лишь текстом
программы и известно на этапе компиляции.
po

Отношение −→ – динамическое, возникает только на этапе
исполнения программы!
sw

Happens-Before для модели памяти
Замкнем по транзитивности:

(︁

sw
−hb→ = −po→ −→

)︁+

,

Получим happens-before – частичный порядок на обращениях
к памяти, который отражает зависимости, заложенные в
программе.

Happens-Before для модели памяти

store(data, 42)

−hb→ load(data)

Естественно ожидать, что чтение data вернет 42.

Visibility

Что увидит чтение?

Visibility
Мы 1) потребовали −→ на атомиках, 2) знаем про зависимости
hb
через −→ для обычных обращений к памяти.
so

Теперь ответим на главный вопрос модели памяти:

Что вернет конкретное чтение load(x) в программе?

Visibility
Мы 1) потребовали −→ на атомиках, 2) знаем про зависимости
hb
через −→ для обычных обращений к памяти.
so

Теперь ответим на главный вопрос модели памяти:

Что вернет конкретное чтение load(x) в программе?

На атомиках чтение возвращает результат последней записи.
Последней – в линейном порядке

−so→.

Visibility через Happens-Before

Для не-атомиков:
Чтение возвращает значение, записанное последней
hb
записью, предшествующей этому чтению в порядке −→.

Visibility через Happens-Before

Все записи в верхнем конусе видны чтениям в нижнем конусе.

Visibility через Happens-Before

Каждое чтение возвращает значение, записанное последней
hb
записью, предшествующей этому чтению в порядке −→.
Что будет, если в одно чтение ведут несколько цепочек

−hb→?

Какую запись читать?

Какую запись читать?

Запретим такие программы!

Формальное определение гонки

Два обращения к памяти конфликтуют, если они
обращаются к одной ячейке и по крайней мере одно из этих
обращений – запись.

Гонкой по данным (data race) называют два
конфликтующих data actions, которые не упорядочены
hb
отношением −→.

Data-Race-Free Programs

Мы запрещаем программы с гонками на data actions!
Если гонок нет, то все конфликтующие обращения к каждой
hb
неатомарной переменной провязаны в цепочку −→.
Иначе говоря, по логике программы все обращения к
переменной происходят упорядоченно.

Программа просит упорядочить все обращения к атомикам, а
дальше сама должна упорядочить остальные обращения к
памяти.

Собираем все вместе

Модель памяти
Наша модель гарантирует:
∙ Линейный порядок для synchronization actions –

−so→

Чтение возвращает последнюю предшествующую запись в
so
порядке −→
∙ Видимость записей через частичный порядок

data actions.

−hb→ для

Чтение возвращает последнюю предшествующую запись в
hb
порядке −→
Программа при этом обещает, что в ней нет гонок.

Формула модели памяти
Линейный порядок на атомиках + видимость через
гонок на data actions.

−hb→ + нет

Формула модели памяти
Линейный порядок на атомиках + видимость через
гонок на data actions.

−hb→ + нет

Почему это дает последовательную согласованность?

Последовательная согласованность

Результат любого исполнения программы такой же, как
при некотором последовательном исполнении операций, в
котором операции каждого потока исполнялись бы в
соответствии с их порядком в программе.

Найдется глобальный линейный порядок обращений к памяти,
∙ который согласован с порядком инструкций в программе,
∙ и каждое чтение возвращает результат последней

предшествующей записи.

Строим последовательное исполнение
Модель памяти гарантирует видимость записей через
hb
so
отношения частичного порядка −→ и −→.
Оба этих порядка согласованы с
другу.

−po→ и не противоречат друг

−hb→ и −so→ можно достроить до линейного порядка T :
(︁

)︁

−hb→ ∪ −so→ ⊂ T

T – кандидат на эквивалентное последовательное исполнение.

Чтение читает последнюю запись

T – кандидат на эквивалентное последовательное исполнение.
Возьмем произвольное чтение r из T и покажем, что оно
возвращает результат последней предшествующей записи в T .
Сам факт предшествования в T пока ничего не означает,
so
hb
видимость записей гарантируется через −→ и −→.

Для атомиков

Возьмем произвольное чтение r из T и покажем, что оно
возвращает результат последней предшествующей записи в T .

Для атомиков это свойство тривиально выполняется, так как
so
все обращения к атомикам упорядочены через −→, а T
so
является продолжением −→.

Для не-атомиков
Возьмем произвольное чтение r из T и покажем, что оно
возвращает результат последней предшествующей записи в T .

Если чтение r – не атомарное, тогда оно читает результат
hb
последней записи в цепочке −→, обозначим эту запись через w .
Запись w

T
−hb→ r , а значит w −→
r.

От противного: пусть найдется запись w ′ , которая находится
между w и r в T .

Для не-атомиков

От противного: пусть найдется запись w ′ , которая находится
между w и r в T .
Ясно, что w ′ −→w , т.к. T – продолжение
hb

−hb→.

Две конфликтующие записи должны быть упорядочены (нет
hb
гонок), а значит w −→ w ′ .
Аналогично можно показать, что w ′

−hb→ r .

Получаем, что w −→ w ′ −→ r , а значит r должно было
прочитать значение, записанное записью w ′ – противоречие.
hb

hb

Результат

Из исполнения в нашей модели получили линейный порядок T
∙ который согласован с порядком инструкций в тексте

программы,
∙ в котором каждое чтение видит значение, записанное

последней предшествующей в T записью.
Таким образом, исполнение последовательно согласованно,
неотличимо от некоторого последовательного исполнения T !

Победа!

Data-Race-Free Programs

Чтобы доказать отсутствие гонок в программе, нужно
hb
построить все варианты частичного порядка −→.
Оказывается, можно проанализировать только
последовательные исполнения и проверить наличие гонок в
них.
Если гонок не будет, то модель памяти гарантирует, что любое
исполнение будет последовательно согласованным.

Оптимизации

Модель памяти SC-DRF гарантирует последовательную
согласованность не для всех программ, а только для программ
без гонок.
Программисту нужно доказывать корректность программы.

Что мы выиграли?

Оптимизации

Модель памяти SC-DRF гарантирует последовательную
согласованность не для всех программ, а только для программ
без гонок.
Программисту нужно доказывать корректность программы.

Что мы выиграли?
Компилятор и процессор получили свободу для оптимизаций!

Локальный порядок для data actions
В программе нет гонок ⇒ поток T ′ не может наблюдать
относительный порядок независимых неатомарных записей в
потоке T между точками синхронизации.

Аналогия с критическими секциями

Перемешиваем data actions

Можем переупорядочить два независимых data actions, если:
∙ Не нарушается логика работы внутри потока
∙ Не выходим за границы synchronization actions

Roach Motel Reordering
Если внести операцию внутрь критической секции, то это
уменьшит параллельность, но не повлияет на корректность
исполнения.

Выносить операции из критической секции, разумеется, не
стоит.

Roach Motel Reordering
Обычные обращения к памяти можно переносить через
синхронизации: назад через записи, вперед через чтения

Для наблюдателя: −→ для исполнения новой программы будет
hb
неотличим от −→ для некоторого исполнения исходной
программы!
hb

Roach Motel Reordering

Локальность реордерингов

Получаем два класса безопасных реордерингов, которые не
нарушают иллюзию последовательного исполнения для
программ без гонок.

Эти оптимизации локальны, они не требуют знания всего
hb
графа предшествования −→.
А значит их может применять компилятор для отдельных
единиц трансляции и процессор прямо на лету исполнения.

Реализация модели памяти
У программиста есть программа, у процессора – своя модель
памяти.
Где и как реализована модель памяти языка?
На уровне библиотеки / компилятора
С помощью специальных инструкций – барьеров памяти
(memory barriers / fences)
Барьеры позволяют ограничить переупорядочивания и
фиксировать записи в памяти.
Точная семантика барьеров и их набор очень сильно зависит
от архитектуры процессора, на каждой архитектуре –
собственный зоопарк.
https://gcc.godbolt.org/

Замечание

Доказывая корректность своих программ, не следует
рассуждать в терминах барьеров памяти и реордерингов.
Эти вещи слишком низкоуровневые, их семантика сильно
зависит от конкретной архитектуры процессора.
Следует пользоваться формальной моделью и рассуждать в
so
hb
терминах видимости через порядки −→ и −→.
Для этого модель и придумали, Карл!

Слабое упорядочивание

В модели памяти C++ помимо Sequential Consistency
поддерживаются еще два ослабленных упорядочивания:
Acquire/Release – отказываемся от глобального
hb
оставляем только частичный порядок −→.

−so→,

Relaxed – на упорядочивание обращений к разным ячейкам
памяти рассчитывать нельзя.

Гонки

Для обозначения ошибок в многопоточных программах
используется два термина: data race и race condition
Это разные ошибки!
Примеры race condition:
∙ Intercepted wakeup в блокирующей очереди
∙ Повторное расширение хэш-таблицы разными потоками

Возникновение race condition возможно и без data race.

Что мы имеем...

Модель памяти

Почитать

∙ Adve, Boehm – Memory Models: A Case for Rethinking

Parallel Languages and Hardware
∙ Boehm, Adve – Foundations of the C++ Concurrency Memory

Model
∙ Алексей Шипилев – Прагматика Java Memory Model
∙ McKenney – Memory Barriers: a Hardware View for Software

Hackers


